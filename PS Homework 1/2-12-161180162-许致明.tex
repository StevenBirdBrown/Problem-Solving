\documentclass{article}
\usepackage{verbatim}
\usepackage{amsfonts}
\usepackage{geometry}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{clrscode3e}
\usepackage{txfonts}
\usepackage{enumerate}
\usepackage{txfonts}
\usepackage{fontspec-xetex}
\usepackage{float}
\geometry{top=2.5cm,bottom=2.5cm,left=2.5cm,right=2.5cm}
\setlength\parindent{0em}
\setmainfont{Times New Roman}
\newcommand*{\dif}{\mathop{}\!\mathrm{d}}
\begin{document}\normalsize
\section*{CS Chapter 5} 
\subsection*{5.5.8}
\begin{enumerate}[a.]
	\item If k$<$n, the probability is 0; If k$\geq$n, the probability is $\frac{\binom{k}{n}\cdot n!}{k^n} = \frac{k^{\underline n}}{k^n}$
	\item If the $i^{th}$ element is the first to collide, then i-1 elements ahead of it mustn't collide. The number of that case is $\binom{k}{i-1}(i-1)!$, then the $i^{th}$ element is bound to collide with one of them, there is $i-1$ cases in which that happens. So the total number of cases is $i\cdot \binom{k}{i-1}(i-1)!=\binom{k}{i-1}i!$, and the whole number of case of hashing i elements is $\binom{k}{i}i!$, so the probability is $\frac{\binom{k}{i-1}i!}{\binom{k}{i}i!}=\frac{i}{k-i+1}$
	\item Assume random variable X denotes the elements number hashed when the first collision happens, then $Pr(X=i)=\frac{\binom{k}{i-1}i!}{\binom{k}{i}i!}=\frac{i}{k-i+1}$, so the expected number of elements hashed when the first collision happens $E(X)=\sum_{i=1}^{n}iPr(X=i)=\sum_{i=1}^{n}\frac{i^2}{k-i+1}$
	\item 
\end{enumerate}
\subsection*{5.5.14}
Define $X_i=I$\{\emph{There is exactly i empty slots}\},
\begin{equation*}
\begin{aligned}
X_i&=\big((1-\frac{1}{k})^k\big)^i\\
&=\big(1-\frac{1}{k}\big)^{ik}
\end{aligned}
\end{equation*}
Therefore, the expected number of empty slots is:
\begin{equation*}
\begin{aligned}
\sum_{i=0}^{2k-1}iX_i&=\sum_{i=0}^{n-1}iPr(X_i)\\
&=\sum_{i=0}^{2k-1}i\big(1-\frac{1}{k}\big)^{ik}\\
&=\frac{(1-\frac{1}{k})\big[1-\big(1-\frac{1}{k}\big)^{(2k-2)k}\big]}{\big[1-\big(1-\frac{1}{k}\big)^k\big]^2}-\frac{\big(1-\frac{1}{k}\big)^k}{\big[\big(1-\frac{1}{k}\big)^k-1\big]}-\frac{(n-1)\big(1-\frac{1}{k}\big)^{nk}}{\big[\big(1-\frac{1}{k}\big)^k-1\big]}
\end{aligned}
\end{equation*}
Denote the equation above as \emph{F(k)}, \[\lim\limits_{k\to\infty}F(k)=\frac{e}{(e-1)^2}\]
\section*{TC Chapter 11}
\subsection*{11.2-3}
It doesn't help to organize the elements in order, since there isn't an efficient algorithm to search a linked list. The time is still $O(1+\frac{n}{k}).$
\subsection*{11.2-6}
We can view the hash table as a two-dimension array $H[m][L]$, in which there is $mL$ grids, but they aren't not all full.
\begin{codebox}
	\zi\proc{Random-Find(\id{H}, \id{x})}\li 
	\textbf{do}\Do\li 
	$\id{i}=\proc{Random(1,\id{m})}$\li 
	$\id{j}=\proc{Random(1,\id{L})}$\End\li 
	\While $H[i][j]\neq x$\li 
	\Return \id{i}, \id{j}
\end{codebox}
\subsection*{11.3-3}
Assume $x=\sum_{i=0}^{s}x_i(2^p)^i, y=\sum_{j=0}^{t}y_j(2^p)^j,$ where s equals t. $X=\{x_1, x_2,\cdots, x_s\}$ is a permutation of $Y=\{y_1, y_2,\cdots, y_s\}$. As the hash function goes, $h(x)=\sum_{i=0}^{s}x_i(2^p)^i$ mod\emph{m}$=\sum_{i=0}^{s}x_i$, while $h(y)=\sum_{i=0}^{s}y_i(2^p)^i$ mod\emph{m}$=\sum_{i=0}^{s}y_i$. Hence $h(x)=h(y)$.\par 
If we store a set of strings in a hash table, this situation is bad for looking for a certain pattern of permutation, since all permutations of the same string is in one slot.
\subsection*{11.3-4}
$h(61)=700$  $h(62)=318$  $h(63)=318$  $h(64)=554$  $h(65)=172$
\subsection*{11.4-2}
Add a satellite data "\emph{deleted}" to $k$:
\begin{codebox}
\zi\proc{Hash-Delete(\id{T}, \id{k})}\li 
$i=0$\li 
\textbf{repeat}\Do\li 
    $j=\proc{h}(k,i)$\li 
    \If $T[j]==k$\Then\li 
        $T[j].deleted=true$\li 
        \Return\li 
    \Else\li 
        $i=i+1$\End\End \li 
\textbf{until} $i=m$ or $T[j]=\const{NIL}$\li 
\textbf{exit} "Element not exist"
\end{codebox}
\begin{codebox}\zi 
	\proc{Hash-Insert(\id{T}, \id{k})}\li 
	$i=0$\li 
	\textbf{repeat}\Do\li 
	$j=\proc{h}(k,i)$\li 
	\If $T[j].deleted$ is true\Then\li  
	$T[j]=k$\li 
	\Return $j$\End\li 
	\If $T[j]==\const{NIL}$\Then\li 
	$T[j]=k$\li 
	\Return $k$\li 
	$i=i+1$\End\End\li 
\textbf{until} $i=m$\li 
\textbf{exit} "Hash table overflow"
\end{codebox}
\subsection*{11.4-3}
Referred to theorem 11.6, when $\alpha=\frac{3}{4}$, the expected probe number is 4; when $\alpha=\frac{7}{8}$, it is 8.
\subsection*{11.1}
\begin{enumerate}[a.]
\item Assume $X$ is time of probing, then $Pr(X>k)=\sum_{i=k+1}^{n}\big(1-\frac{i-1}{m}\big)\leq 2^{-k}\big(1-\frac{1}{2^{n-k}}\big)\leq 2^{-k}$\\
\item \begin{proof}
Let $k=2\log_2{n}$, then $2^{-k}=2^{-2\log_2{n}}=\frac{1}{n^2}$, so the probability is $O(\frac{1}{n^2})$
\end{proof}
\item \begin{proof}
\begin{equation*}
\begin{aligned}
Pr(X>\log_{2}{n})&=Pr(X_1>\log_{2}{n}\cup X_2>\log_{2}{n}\cup \cdots \cup X_n>\log_{2}{n})\\
&=n\cdot O({\frac{1}{n^2}})\\
&=O({\frac{1}{n}})
\end{aligned}
\end{equation*}
\end{proof}
\item \begin{proof}
\begin{equation*}
\begin{aligned}
E(X)&=\sum_{k=1}^{n}k\cdot Pr\{X=k\}\\
&=\sum_{k=1}^{2\log_2{n}}k\cdot Pr\{X=k\}+\sum_{k=2\log_2{n}}^{n}{k\cdot Pr\{X=k\}}\\
&\leq 2\log_2{n}\cdot Pr\{X<k\}+n\cdot Pr\{X=2\log_2{n}\}\cdot (n-\log_2{n})\\
&\leq 2\log_2{n}+n\cdot 2^{-2\log_2{n}}\cdot n\\
&=2\log_2{n}+1\\
&=O(\emph{lg}n)
\end{aligned}
\end{equation*}
\end{proof}
\end{enumerate}
\subsection*{11.2}
\begin{enumerate}[a.]
\item 
\begin{proof}
For a certain element x, the probability of it hashed to a certain slot is $\frac{1}{n}$, and it satisfies binary distribution.\\So the probability $Q_k=\left(\frac{1}{n}\right)^k\left(1-\frac{1}{n}\right)^{n-k}\binom{n}{k}$
\end{proof}
\item \begin{proof}
\begin{equation*}
\begin{aligned}
P_k&=n\cdot Q_k\cdot Q_{<k}^{n-1}\\
&\leq n\cdot Q_k
\end{aligned}
\end{equation*}
\setlength\parindent{4em}($Q_k$ means one slot has less than k elements, which happens exactly $n-1$ times)
\end{proof}
\item \begin{proof}
\begin{equation*}
\begin{aligned}
Q_k&=\left(\frac{1}{n}\right)^k\left(1-\frac{1}{n}\right)^{n-k}\binom{n}{k}\\
&\leq \left(\frac{1}{n}\right)^k\binom{n}{k}\\
&=\frac{n!}{n^k\cdot k!\cdot(n-k)!}\\
&\leq\frac{1}{k!}\\
k!&=\sqrt{2\pi k}\left(\frac{k}{e}\right)\left(1+\Theta(\frac{1}{k})\right)\\
&\geq \frac{e^k}{k^k}\\
Q_k&\leq\frac{1}{k!}\leq{\frac{e^k}{k^k}}
\end{aligned}
\end{equation*}
\end{proof}
\item \begin{proof}
Using the inequalities in c, let $k=k_0=\frac{clgn}{lglgn}$.
\end{proof}
\item \begin{proof}
\begin{equation*}
\begin{aligned}
E(M)&=\sum_{i=1}^{\frac{clgn}{lglgn}}i\cdot Pr\{M=i\}+\sum_{\frac{clgn}{lglgn}+1}^{n}i\cdot Pr\{M=i\}\\
&<\sum_{i=1}^{\frac{clgn}{lglgn}}\frac{clgn}{lglgn}\cdot Pr\{M=i\}+\sum_{\frac{clgn}{lglgn}+1}^{n}n\cdot Pr\{M=i\}\\
&=\frac{clgn}{lglgn}\cdot Pr\{M\leq \frac{clgn}{lglgn}\}+n\cdot Pr\{M>\frac{clgn}{lglgn}\}
\end{aligned}
\end{equation*}
\end{proof}
\end{enumerate}
\end{document} 